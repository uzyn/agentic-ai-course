{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Workshop\n",
    "\n",
    "\n",
    "Outline:\n",
    "1. Basic Prompting\n",
    "2. Intermediate Techniques\n",
    "3. Advanced with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following packages:\n",
    "- `openai` - for OpenAI API interactions\n",
    "- `python-dotenv` - for loading environment variables from .env file\n",
    "- `wikipedia` - for Wikipedia information retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import wikipedia\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Helper function for simple API calls\n",
    "def ask(prompt, model=\"gpt-4o-mini\", temperature=0.7):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with various prompts\n",
    "prompt = \"Hi\"\n",
    "print(ask(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Prompting Techniques\n",
    "\n",
    "### 1.1 Zero-shot Prompting\n",
    "Direct questions without examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot: Direct question\n",
    "prompt = \"Classify this text sentiment: 'The movie was absolutely fantastic!'\"\n",
    "\n",
    "result = ask(prompt)\n",
    "print(\"Zero-shot result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Few-shot Prompting\n",
    "Provide examples to guide the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot: With examples\n",
    "prompt = \"\"\"Classify the sentiment:\n",
    "\n",
    "Text: \"I love this product!\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Text: \"This is terrible.\"\n",
    "Sentiment: Negative\n",
    "\n",
    "Text: \"It's okay, nothing special.\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Text: \"The movie was absolutely fantastic!\"\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "result = ask(prompt)\n",
    "print(\"Few-shot result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Role-based Prompting\n",
    "Assign a specific role or persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without role\n",
    "prompt1 = \"Explain quantum computing\"\n",
    "\n",
    "result1 = ask(prompt1)\n",
    "print(\"Without role:\\n\", result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With role\n",
    "prompt2 = \"You are a teacher explaining to a 10-year-old. Explain quantum computing\"\n",
    "result2 = ask(prompt2)\n",
    "print(\"With role (teacher to 10-year-old):\\n\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Clear Instructions\n",
    "Be specific about what you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vague instruction\n",
    "vague = \"Tell me about Paris. Where should I go?\"\n",
    "print(\"Vague:\", ask(vague), \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear instruction\n",
    "clear = \"List exactly 3 tourist attractions in Paris with one sentence description each\"\n",
    "print(\"Clear:\\n\", ask(clear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Intermediate Techniques\n",
    "\n",
    "### 2.1 Chain-of-Thought (CoT) Prompting\n",
    "Ask the model to think step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without CoT\n",
    "prompt1 = \"Estimate how many taxis are actively carrying passengers in Singapore at 8:00 pm on a weekday. Provide a single numeric estimate.\"\n",
    "print(\"Without CoT:\")\n",
    "print(ask(prompt1), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With CoT\n",
    "prompt2 = \"\"\"\n",
    "Q:\n",
    "\n",
    "A:\n",
    "\n",
    "Q: Estimate how many taxis are actively carrying passengers in Singapore at 8:00 pm on a weekday. Provide a single numeric estimate. Think clearly step by step.\n",
    "\n",
    "A:\n",
    "\"\"\" # Input further prompt that encourages chain-of-thought reasoning\n",
    "print(\"With CoT:\")\n",
    "print(ask(prompt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Step-by-Step Reasoning\n",
    "Break complex tasks into steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are doing a Fermi estimate for Singapore at 8:00 pm on a weekday.\n",
    "Reason step by step:\n",
    "\t1.\n",
    "  2.\n",
    "  3. \"\"\"\n",
    "\n",
    "result = ask(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Output Formatting\n",
    "Request specific output formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON output\n",
    "prompt = \"\"\"Extract information from this text and return as JSON:\n",
    "\n",
    "\"John Smith, 28 years old, works as a software engineer in San Francisco.\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result = ask(prompt)\n",
    "print(result)\n",
    "\n",
    "try:\n",
    "    data = json.loads(result)\n",
    "    print(\"\\n✅ Valid JSON parsed:\", data)\n",
    "except:\n",
    "    print(\"\\n❌ Invalid JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List output\n",
    "prompt = \"\"\"Generate a numbered list of 5 healthy breakfast options.\n",
    "Format: Number. Item - Brief description (max 10 words)\"\"\"\n",
    "\n",
    "result = ask(prompt)\n",
    "print(\"List Output:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Advanced with Tools\n",
    "\n",
    "### 3.1 System vs User Prompts\n",
    "Using system messages for consistent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_system(system_prompt, user_prompt, temperature=0.7):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example: Consistent pirate responses\n",
    "system = \"You are a pirate. Always respond in pirate speak.\"\n",
    "user1 = \"What's the weather like?\"\n",
    "user2 = \"How do I cook pasta?\"\n",
    "\n",
    "print(\"Question 1:\", user1)\n",
    "print(\"Response:\", ask_with_system(system, user1))\n",
    "print(\"\\nQuestion 2:\", user2)\n",
    "print(\"Response:\", ask_with_system(system, user2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Temperature Control\n",
    "Controlling randomness in outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a one-sentence tagline for a coffee shop\"\n",
    "\n",
    "# Low temperature (0.1) - More deterministic\n",
    "print(\"Low temperature (0.1) - Consistent:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}. {ask(prompt, temperature=0.1)}\")\n",
    "\n",
    "print(\"\\nHigh temperature (1.0) - Creative:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}. {ask(prompt, temperature=1.0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Wikipedia for Information Retrieval\n",
    "Using Wikipedia API to get factual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Wikipedia to get factual information\n",
    "def get_article(search_term):\n",
    "    \"\"\"Search Wikipedia and retrieve article content\"\"\"\n",
    "    try:\n",
    "        # Search for articles\n",
    "        results = wikipedia.search(search_term)\n",
    "        if not results:\n",
    "            return f\"No Wikipedia articles found for '{search_term}'\"\n",
    "\n",
    "        # Get the first result\n",
    "        first_result = results[0]\n",
    "        page = wikipedia.page(first_result, auto_suggest=False)\n",
    "\n",
    "        # Return the content (you can also access page.summary for a shorter version)\n",
    "        return page.content\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        # Handle disambiguation pages\n",
    "        return f\"Multiple options found: {e.options[:5]}\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"Page not found for '{search_term}'\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example: Get information from Wikipedia\n",
    "print(\"Searching Wikipedia for information...\\n\")\n",
    "article = get_article(\"Artificial intelligence\")\n",
    "\n",
    "# Display first 1000 characters\n",
    "print(\"Article preview:\")\n",
    "print(article[:1000] if len(article) > 1000 else article)\n",
    "print(\"...\")\n",
    "\n",
    "# You can also get just the summary\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Summary version:\")\n",
    "summary = wikipedia.summary(\"Artificial intelligence\", sentences=3)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Wikipedia with OpenAI for enhanced analysis\n",
    "def wiki_enhanced_analysis(topic):\n",
    "    \"\"\"Use Wikipedia data with OpenAI for comprehensive analysis\"\"\"\n",
    "\n",
    "    # Get Wikipedia information\n",
    "    wiki_content = get_article(topic)\n",
    "\n",
    "    # Truncate content if too long (to fit in context window)\n",
    "    max_chars = 3000\n",
    "    if len(wiki_content) > max_chars:\n",
    "        wiki_content = wiki_content[:max_chars] + \"...\"\n",
    "\n",
    "    # Use OpenAI to analyze the Wikipedia content\n",
    "    prompt = f\"\"\"Based on the following Wikipedia information about '{topic}':\n",
    "\n",
    "{wiki_content}\n",
    "\n",
    "Please provide:\n",
    "1. A concise summary (2-3 sentences)\n",
    "2. Three key facts\n",
    "3. Why this topic is important\n",
    "\n",
    "Format your response clearly with numbered sections.\"\"\"\n",
    "\n",
    "    analysis = ask(prompt, temperature=0.3)\n",
    "    return analysis\n",
    "\n",
    "# Example: Analyze a topic using Wikipedia + OpenAI\n",
    "print(\"=== Wikipedia-Enhanced Analysis Demo ===\\n\")\n",
    "topic = \"Artificial intelligence\"\n",
    "print(f\"Analyzing: {topic}\\n\")\n",
    "result = wiki_enhanced_analysis(topic)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Combining Techniques\n",
    "Using multiple techniques together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex prompt combining multiple techniques with Wikipedia\n",
    "def complex_analysis_with_wiki(topic):\n",
    "    \"\"\"Analyze a topic using Wikipedia data and multiple prompting techniques\"\"\"\n",
    "\n",
    "    # Try to get Wikipedia information first\n",
    "    try:\n",
    "        wiki_summary = wikipedia.summary(topic, sentences=5)\n",
    "        has_wiki_data = True\n",
    "    except:\n",
    "        wiki_summary = \"No Wikipedia data available.\"\n",
    "        has_wiki_data = False\n",
    "\n",
    "    # Create a comprehensive prompt\n",
    "    system_prompt = \"You are an expert analyst. Be concise and structured.\"\n",
    "\n",
    "    if has_wiki_data:\n",
    "        user_prompt = f\"\"\"Analyze '{topic}' using this format:\n",
    "\n",
    "Wikipedia Information:\n",
    "{wiki_summary}\n",
    "\n",
    "Based on the above information and your knowledge, provide:\n",
    "1. Current Status (integrate Wikipedia facts with your knowledge)\n",
    "2. Key Players (list top 3)\n",
    "3. Future Outlook (brief prediction)\n",
    "\n",
    "Think step-by-step and provide a structured analysis.\"\"\"\n",
    "    else:\n",
    "        user_prompt = f\"\"\"Analyze '{topic}' using this format:\n",
    "\n",
    "1. Current Status (based on your knowledge)\n",
    "2. Key Players (list top 3)\n",
    "3. Future Outlook (brief prediction)\n",
    "\n",
    "Think step-by-step and provide a structured analysis.\"\"\"\n",
    "\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example analysis\n",
    "topic = \"Artificial intelligence\"\n",
    "print(f\"Analysis of: {topic}\\n\")\n",
    "print(complex_analysis_with_wiki(topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Best Practices\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Start Simple**: Zero-shot often works well for basic tasks\n",
    "2. **Add Examples**: Few-shot helps with consistency\n",
    "3. **Be Specific**: Clear instructions get better results\n",
    "4. **Think Step-by-Step**: CoT improves reasoning\n",
    "5. **Format Output**: Structure makes responses more useful\n",
    "6. **Use External Data**: Wikipedia provides factual information\n",
    "7. **Control Temperature**: Balance creativity vs consistency\n",
    "\n",
    "### Quick Reference:\n",
    "- **Temperature**: 0.0-0.3 (factual), 0.7 (balanced), 1.0+ (creative)\n",
    "- **System Prompts**: Set consistent behavior\n",
    "- **User Prompts**: Specific queries\n",
    "- **Chain-of-Thought**: Add \"Think step-by-step\"\n",
    "- **Few-shot**: 2-5 examples usually sufficient\n",
    "- **Wikipedia**: Use for factual, encyclopedic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise\n",
    "\n",
    "Try creating your own prompt that combines multiple techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Create a prompt that:\n",
    "# 1. Uses a role\n",
    "# 2. Includes few-shot examples\n",
    "# 3. Requests specific formatting\n",
    "# 4. Uses chain-of-thought\n",
    "\n",
    "your_prompt = \"\"\"\n",
    "# YOUR PROMPT HERE\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment to test:\n",
    "# result = ask(your_prompt)\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
