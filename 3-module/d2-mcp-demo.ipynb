{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Model Context Protocol (MCP) Demo\n",
    "\n",
    "This notebook demonstrates the **Model Context Protocol (MCP)** - an open standard for connecting AI models to external tools and data sources.\n",
    "\n",
    "## This Demo\n",
    "\n",
    "We'll use the **Singapore Weather MCP Server** (`d2-sgweather-mcp/`) which:\n",
    "- Fetches real weather data from data.gov.sg\n",
    "- Runs as a Node.js stdio MCP process\n",
    "- Provides the `get_singapore_weather` tool\n",
    "\n",
    "## Required Environment Variables\n",
    "\n",
    "```\n",
    "ANTHROPIC_API_KEY    # Your Anthropic API key (required)\n",
    "```\n",
    "\n",
    "Please refer to the [README](README.md) for instructions on setting up environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hz5hxtn1ifg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running standalone without the project setup:\n",
    "# !pip install anthropic python-dotenv\n",
    "\n",
    "# IMPORTANT: The MCP server requires Node.js\n",
    "# Install the sgweather-mcp server dependencies:\n",
    "# cd sgweather-mcp && npm install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize Anthropic client\n",
    "client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "\n",
    "print(\"‚úÖ Anthropic client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-concept",
   "metadata": {},
   "source": [
    "## MCP Server Setup\n",
    "\n",
    "The Singapore Weather MCP Server is located in `d2-sgweather-mcp/` and runs as a Node.js process. \n",
    "\n",
    "Anthropic's client launches the Node.js server as a subprocess when needed. Communication happens through standard input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcp-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "server_path = os.path.abspath(\"d2-sgweather-mcp/server.js\")\n",
    "print(f\"MCP Server location: {server_path}\")\n",
    "print(f\"Server exists: {os.path.exists(server_path)}\")\n",
    "\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run([\"node\", \"--version\"], capture_output=True, text=True)\n",
    "    print(f\"Node.js version: {result.stdout.strip()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Node.js not found! Please install Node.js to run the MCP server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-demo",
   "metadata": {},
   "source": [
    "## Connecting to the MCP Server\n",
    "\n",
    "We'll connect to the MCP server using the MCP Python client. The client will:\n",
    "1. Spawn the Node.js server as a subprocess\n",
    "2. Communicate via stdio (standard input/output)\n",
    "3. Discover available tools\n",
    "4. Execute tool calls as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-weather-demo",
   "metadata": {},
   "source": [
    "## MCP Demo: Singapore Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xmi1g1zjp6j",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the MCP server\n",
    "server_path = os.path.abspath(\"d2-sgweather-mcp/server.js\")\n",
    "\n",
    "# MCP Server parameters\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"node\",\n",
    "    args=[server_path],\n",
    "    env=None\n",
    ")\n",
    "\n",
    "async def get_mcp_tools():\n",
    "    \"\"\"Connect to MCP server and get available tools\"\"\"\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            # List available tools from the MCP server\n",
    "            tools_list = await session.list_tools()\n",
    "            return tools_list\n",
    "\n",
    "# Get tools from MCP server\n",
    "print(\"\\nüîç Discovering tools from MCP server...\")\n",
    "tools_response = await get_mcp_tools()\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(tools_response.tools)} tool(s):\")\n",
    "for tool in tools_response.tools:\n",
    "    print(f\"  - {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uoxf3j07m2o",
   "metadata": {},
   "source": [
    "## Convert MCP Tools for Claude\n",
    "\n",
    "Now we'll convert the MCP tool definitions into the format Claude expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7si4yjfte1i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MCP tools to Claude's tool format\n",
    "claude_tools = []\n",
    "for tool in tools_response.tools:\n",
    "    claude_tool = {\n",
    "        \"name\": tool.name,\n",
    "        \"description\": tool.description,\n",
    "        \"input_schema\": tool.inputSchema\n",
    "    }\n",
    "    claude_tools.append(claude_tool)\n",
    "\n",
    "print(json.dumps(claude_tools, indent=2))\n",
    "\n",
    "# Create a function to execute tools via MCP\n",
    "async def execute_mcp_tool(tool_name, tool_args):\n",
    "    print(tool_name)\n",
    "    print(tool_args)\n",
    "    \"\"\"Execute a tool via the MCP server\"\"\"\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            # Call the tool\n",
    "            result = await session.call_tool(tool_name, arguments=tool_args)\n",
    "            return result\n",
    "\n",
    "\n",
    "# Try to execute\n",
    "weather = await execute_mcp_tool(\"get_singapore_weather\", {})\n",
    "print(weather)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cryi02txr7a",
   "metadata": {},
   "source": [
    "## Comparison: Claude Without MCP vs With MCP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zbmilpz4lph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo 1: WITHOUT MCP - Claude has no access to real-time data\n",
    "async def chat_without_mcp(user_question):\n",
    "    \"\"\"Chat with Claude WITHOUT MCP tools\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_question}\n",
    "    ]\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    print(\"ü§ñ Claude's Response (without MCP):\\n\")\n",
    "    for block in response.content:\n",
    "      if hasattr(block, 'text'):\n",
    "        print(block.text)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "user_question = \"What's the weather like in Singapore today? Give me a brief summary.\"\n",
    "print(f\"üë§ User: {user_question}\\n\")\n",
    "await chat_without_mcp(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anthropic-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_mcp(user_message):\n",
    "    \"\"\"Have a conversation with Claude using MCP tools\"\"\"\n",
    "    print(f\"üë§ User: {user_message}\\n\")\n",
    "\n",
    "    # Initial request to Claude\n",
    "    messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "        max_tokens=1024,\n",
    "        tools=claude_tools, # Notice the tools are included here\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # Process the response\n",
    "    while response.stop_reason == \"tool_use\":\n",
    "        # Extract tool calls\n",
    "        tool_use_blocks = [block for block in response.content if block.type == \"tool_use\"]\n",
    "\n",
    "        if not tool_use_blocks:\n",
    "            break\n",
    "\n",
    "        print(\"üîß Claude is using MCP tools:\\n\")\n",
    "\n",
    "        # Add assistant's response to messages\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "        # Execute each tool via MCP\n",
    "        tool_results = []\n",
    "        for tool_block in tool_use_blocks:\n",
    "            tool_name = tool_block.name\n",
    "            tool_args = tool_block.input\n",
    "\n",
    "            print(f\"  Tool: {tool_name}\")\n",
    "            print(f\"  Args: {json.dumps(tool_args, indent=4)}\")\n",
    "\n",
    "            # Execute via MCP server\n",
    "            result = await execute_mcp_tool(tool_name, tool_args)\n",
    "\n",
    "            # Extract content from result\n",
    "            if result.content:\n",
    "                content_text = \"\"\n",
    "                for content_item in result.content:\n",
    "                    if hasattr(content_item, 'text'):\n",
    "                        content_text += content_item.text\n",
    "\n",
    "                print(f\"  ‚úÖ Result from MCP server: {content_text[:150]}...\")\n",
    "\n",
    "                tool_results.append({\n",
    "                    \"type\": \"tool_result\",\n",
    "                    \"tool_use_id\": tool_block.id,\n",
    "                    \"content\": content_text\n",
    "                })\n",
    "\n",
    "        # Add tool results and get Claude's final response\n",
    "        messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-haiku-20241022\",\n",
    "            max_tokens=1024,\n",
    "            tools=claude_tools,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Display Claude's final response\n",
    "    print(\"ü§ñ Claude's Response (with MCP):\\n\")\n",
    "    for block in response.content:\n",
    "        if hasattr(block, 'text'):\n",
    "            print(block.text)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "await chat_with_mcp(\"What's the weather like in Singapore today? Give me a brief summary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "umbrella_question = \"Should I bring an umbrella today in Singapore? Also, what are the temperature and humidity levels?\"\n",
    "\n",
    "await chat_without_mcp(umbrella_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52331bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(umbrella_question)\n",
    "await chat_with_mcp(umbrella_question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
