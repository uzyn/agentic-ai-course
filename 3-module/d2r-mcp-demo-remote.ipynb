{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# MCP Network Demo (Streamable HTTP Transport)\n",
    "\n",
    "This notebook demonstrates connecting to a **remote MCP server** over the network using Streamable HTTP, in contrast to the stdio transport in d2-mcp-demo.\n",
    "\n",
    "We'll connect to CoinGecko's public MCP server (no API key required).\n",
    "\n",
    "See https://docs.coingecko.com/docs/mcp-server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "logging.getLogger(\"mcp.client.streamable_http\").setLevel(logging.ERROR)\n",
    "\n",
    "MCP_SERVER_URL = \"https://mcp.api.coingecko.com/mcp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-tools",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def list_remote_tools():\n",
    "    \"\"\"Connect to remote MCP server and list available tools\"\"\"\n",
    "    async with streamablehttp_client(url=MCP_SERVER_URL) as (read, write, _):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            tools = await session.list_tools()\n",
    "            return tools\n",
    "\n",
    "tools_response = await list_remote_tools()\n",
    "\n",
    "print(f\"Found {len(tools_response.tools)} tools:\\n\")\n",
    "for tool in tools_response.tools:\n",
    "    print(f\"- {tool.name}\")\n",
    "    print(f\"  {tool.description}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "call-tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_remote_tool(tool_name: str, args: dict):\n",
    "    \"\"\"Execute a tool on the remote MCP server\"\"\"\n",
    "    async with streamablehttp_client(url=MCP_SERVER_URL) as (read, write, _):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            result = await session.call_tool(tool_name, arguments=args)\n",
    "            return result\n",
    "\n",
    "# Get Bitcoin price\n",
    "result = await call_remote_tool(\"get_simple_price\", {\"ids\": \"bitcoin\", \"vs_currencies\": \"usd\"})\n",
    "\n",
    "for content in result.content:\n",
    "    if hasattr(content, 'text'):\n",
    "        data = json.loads(content.text)\n",
    "        print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rmz859dtv4",
   "metadata": {},
   "source": [
    "## Agentic Pattern: LLM + MCP Tools\n",
    "\n",
    "The previous cells called MCP tools directly with hardcoded parameters. Now we'll let **Claude** decide which tools to call and how to interpret the results.\n",
    "\n",
    "This is the core agentic pattern:\n",
    "1. Send a question and available tools to Claude\n",
    "2. Claude decides which tool(s) to call and with what parameters\n",
    "3. We execute the tool calls via MCP and feed results back\n",
    "4. Claude reasons over the data and provides a final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wzyjnjf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "\n",
    "# Convert MCP tools to Claude's tool format\n",
    "claude_tools = []\n",
    "for tool in tools_response.tools:\n",
    "    claude_tools.append({\n",
    "        \"name\": tool.name,\n",
    "        \"description\": tool.description,\n",
    "        \"input_schema\": tool.inputSchema\n",
    "    })\n",
    "\n",
    "print(f\"Registered {len(claude_tools)} tools for Claude\")\n",
    "\n",
    "claude_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4r2p79hcazl",
   "metadata": {},
   "source": [
    "## Ask Claude: BTC vs ETH in the Last 24 Hours\n",
    "\n",
    "We'll ask Claude to compare BTC and ETH performance. Claude will autonomously:\n",
    "- Determine which MCP tool(s) to call\n",
    "- Choose the right parameters (e.g. requesting 24h change data)\n",
    "- Analyze the results and provide a reasoned answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3q8j51kj1lm",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_claude_with_mcp(question: str):\n",
    "    \"\"\"Send a question to Claude, letting it use MCP tools to gather data.\"\"\"\n",
    "    print(f\"Question: {question}\\n\")\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "        max_tokens=1024,\n",
    "        tools=claude_tools,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # Agentic loop: keep going while Claude wants to use tools\n",
    "    while response.stop_reason == \"tool_use\":\n",
    "        tool_use_blocks = [block for block in response.content if block.type == \"tool_use\"]\n",
    "\n",
    "        if not tool_use_blocks:\n",
    "            break\n",
    "\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
    "\n",
    "        # Execute each tool call via the remote MCP server\n",
    "        tool_results = []\n",
    "        for tool_block in tool_use_blocks:\n",
    "            tool_name = tool_block.name\n",
    "            tool_args = tool_block.input\n",
    "\n",
    "            print(f\"  Tool call: {tool_name}\")\n",
    "            print(f\"  Arguments: {json.dumps(tool_args, indent=4)}\")\n",
    "\n",
    "            result = await call_remote_tool(tool_name, tool_args)\n",
    "\n",
    "            content_text = \"\"\n",
    "            for item in result.content:\n",
    "                if hasattr(item, 'text'):\n",
    "                    content_text += item.text\n",
    "\n",
    "            print(f\"  Result: {content_text[:200]}...\\n\")\n",
    "\n",
    "            tool_results.append({\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_block.id,\n",
    "                \"content\": content_text\n",
    "            })\n",
    "\n",
    "        # Feed tool results back to Claude\n",
    "        messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "\n",
    "        response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-5-haiku-20241022\",\n",
    "            max_tokens=1024,\n",
    "            tools=claude_tools,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "    for block in response.content:\n",
    "        if hasattr(block, 'text'):\n",
    "            print(block.text)\n",
    "\n",
    "await ask_claude_with_mcp(\n",
    "    \"Which asset performed better over the last 24 hours, BTC or ETH?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
